{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Party Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, Imputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Custom Classes\n",
    "\n",
    "The following classes were created in the Data Cleaning notebook, they are used to assist in the creation of a pipeline that cleans the data and prepares it for models.\n",
    "\n",
    "The basis for FeatureExtractor classes where provided by Richard, upon which I expanded. CategoricalExtractor was given by Richard as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultipleFeaturesExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.cols].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultipleFeaturesMap(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols, vals):\n",
    "        self.cols = cols\n",
    "        self.vals = vals\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        df = X[self.cols].copy()\n",
    "        for col in self.cols:\n",
    "            df[col] = X[col].map(self.vals)\n",
    "            \n",
    "        return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureMap(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column, vals):\n",
    "        self.column = column\n",
    "        self.vals = vals\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column].map(self.vals).values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CategoricalExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        self.values = None\n",
    "        \n",
    "    def _create_values(self, indices):\n",
    "        return {ind: i+1 for i, ind in enumerate(indices)}\n",
    "    \n",
    "    def _apply_values(self, row_val):\n",
    "        return self.values.get(row_val, 0)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.values = self._create_values(X[self.column].value_counts().index)\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        col = X[self.column].apply(self._apply_values)\n",
    "        return col.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Function\n",
    "\n",
    "The following function was created in the Data Cleaning notebook, it is used to assist in the creation of a pipeline that cleans the data and prepares it for models, returning the data as a FeatureUnion object. It contains predefined lists, that tell it how to operate in the ways I determined best during EDA. That it takes the columns of the data as input is not necessary, I simply found it preferable to hard coding yet another list of columns inside the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createFU(cols):\n",
    "    '''\n",
    "    With the columns of the Ames data, create a Feature Union in a more automated way to clean the data.\n",
    "    Returns a FeatureUnion that should have clean and expanded data that can then be used in a pipeline with a model\n",
    "    '''\n",
    "    #remove columns I don't want to deal with, deciding because too many null during EDA\n",
    "    cols = [col for col in cols if col not in ['Id','PID','Alley','Misc Feature','Fireplace Qu','Pool QC','Fence']]\n",
    "    #create lists of cols gotten from EDA\n",
    "    ord_cols_qual = ['Exter Qual','Exter Cond','Bsmt Qual','Bsmt Cond',\n",
    "                 'Heating QC','Kitchen Qual','Garage Qual','Garage Cond']\n",
    "    ord_cols_type = ['BsmtFin Type 1', 'BsmtFin Type 2']\n",
    "    ord_cols_unique = [('Lot Shape', {'IR1': 2, 'IR2': 1, 'IR3': 0, 'Reg': 3}),\n",
    "                         ('Utilities', {'AllPub': 3, 'ELO': 0, 'NoSeWa': 1, 'NoSewr': 2}),\n",
    "                         ('Land Slope', {'Gtl': 2, 'Mod': 1, 'Sev': 0}),\n",
    "                         ('Bsmt Exposure', {'Av': 3, 'Gd': 4, 'Mn': 2, 'NA': 0, 'No': 1}),\n",
    "                         ('Central Air', {'N': 0, 'Y': 1}),\n",
    "                         ('Electrical', {'FuseA': 3, 'FuseF': 2, 'FuseP': 1, 'Mix': 0, 'SBrkr': 4}),\n",
    "                         ('Functional',\n",
    "                          {'Maj1': 3,'Maj2': 2,'Min1': 6,'Min2': 5,'Mod': 4,'Sal': 0,'Sev': 1,'Typ': 7}),\n",
    "                         ('Garage Finish', {'Fin': 3, 'NA': 0, 'RFn': 2, 'Unf': 1}),\n",
    "                         ('Paved Drive', {'N': 0, 'P': 1, 'Y': 2})]\n",
    "    nominal_cols = ['MS Zoning','Street','Land Contour','Lot Config','Neighborhood',\n",
    "                    'Condition 1','Condition 2','Bldg Type','House Style','Roof Style',\n",
    "                    'Roof Matl','Exterior 1st','Exterior 2nd','Mas Vnr Type','Foundation',\n",
    "                    'Heating','Garage Type','Sale Type']\n",
    "    \n",
    "    #get all the columns that are not objects/not doing anything special with\n",
    "    obj_cols = (ord_cols_qual+ord_cols_type+[y[0] for y in ord_cols_unique]+nominal_cols)\n",
    "    num_cols = [col for col in cols if col not in obj_cols]\n",
    "    \n",
    "    #create list to hold pipelines\n",
    "    pipes = []\n",
    "    \n",
    "    #create pipe for qualities\n",
    "    qual_pipe = make_pipeline(\n",
    "                    MultipleFeaturesMap(ord_cols_qual, \n",
    "                                       {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}),\n",
    "                    Imputer()\n",
    "                    )\n",
    "    pipes.append(('qual_pipe', qual_pipe))\n",
    "    \n",
    "    #create pipe for type\n",
    "    type_pipe = make_pipeline(\n",
    "                    MultipleFeaturesMap(ord_cols_type, \n",
    "                                       {'NA':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6}),\n",
    "                    Imputer()\n",
    "                    )\n",
    "    pipes.append(('type_pipe', type_pipe))\n",
    "    \n",
    "    #just get all the data from numerical columns\n",
    "    num_pipe = make_pipeline(\n",
    "                    MultipleFeaturesExtractor(num_cols),\n",
    "                    Imputer()\n",
    "                    )\n",
    "    pipes.append(('num_pipe', num_pipe))\n",
    "    \n",
    "    #iterate over unique columns adding new pipelines for each    \n",
    "    for col, vals in ord_cols_unique:\n",
    "        tmp_pipe = make_pipeline(\n",
    "                        FeatureMap(col, vals),\n",
    "                        Imputer()\n",
    "                        )\n",
    "        pipes.append(('{}_pipe'.format(col), tmp_pipe))\n",
    "        \n",
    "    #turn nominal columns into dummies and add pipelines for each\n",
    "    for col in nominal_cols:\n",
    "        tmp_pipe = make_pipeline(\n",
    "                        CategoricalExtractor(col),\n",
    "                        Imputer(strategy='median'),\n",
    "                        OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "                        )\n",
    "        pipes.append(('{}_pipe'.format(col), tmp_pipe))\n",
    "    \n",
    "    return FeatureUnion(pipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "Here I will load the data, both the training and test files. The purpose of loading both is my intention to brute force the kaggle competition with many models which I will save predictions for along the way in case of any crashes, which means I will need the test data loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "train_df = pd.read_csv('datasets/train.csv')\n",
    "\n",
    "#save the training X without either target variable, then save the encoded classifier target\n",
    "train_X = train_df.drop(['Sale Condition', 'SalePrice'], axis=1)\n",
    "train_y = train_df['Sale Condition'].apply(lambda x: 1 if x=='Abnorml' else 0)\n",
    "\n",
    "#test data requires no changes\n",
    "test_df = pd.read_csv('datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for graphing purposes I will also split train test\n",
    "Xtr, Xte, ytr, yte = train_test_split(train_X, train_y, random_state=42, stratify=train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the FeatureUnion that will contain the pipelines for cleaning the data. The intention is that this serves as the basis for modeling pipelines, and should remain unchanged throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_fu = createFU(train_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Within this section I will use the pipelines and gridsearch to fit many models. I reiterate that the intent is to succeed through \"directed\" brute force. Every model shall have it's own section where I use gridsearch to fit it to the training data, predict the test data, and save each to a respective csv.\n",
    "\n",
    "Afterwards I create a single instance of the estimator, using the best paramters, to create a confusion matrix. The reason for doing this with a new version of the model is to create a static version of the model so there is no need to rerun the GridSearches again to refind the model upon closing the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Baseline\n",
    "\n",
    "Just going to guess all 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictions dataframe\n",
    "pred = pd.DataFrame()\n",
    "pred['Id'] = test_df.Id\n",
    "pred['Sale Condition'] = 0\n",
    "\n",
    "#to csv\n",
    "pred.to_csv('ClassSubs/Zeros.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.93567251462\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_not_abnormal</th>\n",
       "      <th>predicted_abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_abnormal</th>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_abnormal</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_not_abnormal  predicted_abnormal\n",
       "not_abnormal                     480                   0\n",
       "is_abnormal                       33                   0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = Xte['Id'].apply(lambda x: 0)\n",
    "print('Accuracy', accuracy_score(yte, preds))\n",
    "\n",
    "conmat = np.array(confusion_matrix(yte, preds, labels=[0,1]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['not_abnormal', 'is_abnormal'],\n",
    "                         columns=['predicted_not_abnormal', 'predicted_abnormal'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the structure of the pipeline so it can be easily gridsearched\n",
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', None),\n",
    "    #('selectkbest', SelectKBest(score_func=f_classif, k=5)),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "#create parameters\n",
    "params = {\n",
    "    'scaling': [None, StandardScaler(), RobustScaler()],\n",
    "    #'selectkbest__k':[2, 5, 10, 15, 20, 25, 30, 40, 50, 75, 100, 150, 'all'],\n",
    "    'model__fit_intercept':[False, True],\n",
    "    'model__penalty':['l1', 'l2'],\n",
    "    'model__C': np.linspace(0.01, 100, 15)\n",
    "}\n",
    "\n",
    "gs1 = GridSearchCV(modeling_pipe, params, verbose=1, cv=5, n_jobs=-1)\n",
    "gs1.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940516821063\n",
      "{'model__C': 0.01, 'model__fit_intercept': True, 'model__penalty': 'l2', 'scaling': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "print(gs1.best_score_)\n",
    "print(gs1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create predictions dataframe\n",
    "pred = pd.DataFrame()\n",
    "pred['Id'] = test_df.Id\n",
    "pred['Sale Condition'] = gs1.best_estimator_.predict(test_df)\n",
    "\n",
    "#to csv\n",
    "pred.to_csv('ClassSubs/LogReg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.937621832359\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_not_abnormal</th>\n",
       "      <th>predicted_abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_abnormal</th>\n",
       "      <td>475</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_abnormal</th>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_not_abnormal  predicted_abnormal\n",
       "not_abnormal                     475                   5\n",
       "is_abnormal                       27                   6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('model', LogisticRegression(C=.01, penalty='l2'))\n",
    "])\n",
    "modeling_pipe.fit(Xtr, ytr)\n",
    "preds = modeling_pipe.predict(Xte)\n",
    "print('Accuracy', accuracy_score(yte, preds))\n",
    "\n",
    "conmat = np.array(confusion_matrix(yte, preds, labels=[0,1]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['not_abnormal', 'is_abnormal'],\n",
    "                         columns=['predicted_not_abnormal', 'predicted_abnormal'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the structure of the pipeline so it can be easily gridsearched\n",
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', None),\n",
    "    ('selectkbest', SelectKBest(score_func=f_classif, k=5)),\n",
    "    ('model', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "#create parameters\n",
    "params = {\n",
    "    'scaling': [None, StandardScaler(), RobustScaler()],\n",
    "    'selectkbest__k':[5, 10, 25, 50, 75, 100, 150, 'all'],\n",
    "    'model__n_neighbors':[2, 4, 5, 10, 25, 50],\n",
    "    'model__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(modeling_pipe, params, verbose=1, cv=5, n_jobs=-1)\n",
    "gs2.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.938078985861\n",
      "{'model__n_neighbors': 4, 'model__weights': 'uniform', 'scaling': StandardScaler(copy=True, with_mean=True, with_std=True), 'selectkbest__k': 50}\n"
     ]
    }
   ],
   "source": [
    "print(gs2.best_score_)\n",
    "print(gs2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictions dataframe\n",
    "pred = pd.DataFrame()\n",
    "pred['Id'] = test_df.Id\n",
    "pred['Sale Condition'] = gs2.best_estimator_.predict(test_df)\n",
    "\n",
    "#to csv\n",
    "pred.to_csv('ClassSubs/KNNClass.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.927875243665\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_not_abnormal</th>\n",
       "      <th>predicted_abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_abnormal</th>\n",
       "      <td>475</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_abnormal</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_not_abnormal  predicted_abnormal\n",
       "not_abnormal                     475                   5\n",
       "is_abnormal                       32                   1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('selectkbest', SelectKBest(score_func=f_classif, k=50)),\n",
    "    ('model', KNeighborsClassifier(n_neighbors=4))\n",
    "])\n",
    "modeling_pipe.fit(Xtr, ytr)\n",
    "preds = modeling_pipe.predict(Xte)\n",
    "print('Accuracy', accuracy_score(yte, preds))\n",
    "\n",
    "conmat = np.array(confusion_matrix(yte, preds, labels=[0,1]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['not_abnormal', 'is_abnormal'],\n",
    "                         columns=['predicted_not_abnormal', 'predicted_abnormal'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.933723196881\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_not_abnormal</th>\n",
       "      <th>predicted_abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_abnormal</th>\n",
       "      <td>479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_abnormal</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_not_abnormal  predicted_abnormal\n",
       "not_abnormal                     479                   1\n",
       "is_abnormal                       33                   0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('model', SVC())\n",
    "])\n",
    "modeling_pipe.fit(Xtr, ytr)\n",
    "preds = modeling_pipe.predict(Xte)\n",
    "print('Accuracy', accuracy_score(yte, preds))\n",
    "\n",
    "conmat = np.array(confusion_matrix(yte, preds, labels=[0,1]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['not_abnormal', 'is_abnormal'],\n",
    "                         columns=['predicted_not_abnormal', 'predicted_abnormal'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create predictions dataframe\n",
    "pred = pd.DataFrame()\n",
    "pred['Id'] = test_df.Id\n",
    "pred['Sale Condition'] = modeling_pipe.predict(test_df)\n",
    "\n",
    "#to csv\n",
    "pred.to_csv('ClassSubs/SVClass.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the structure of the pipeline so it can be easily gridsearched\n",
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', None),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "#create parameters\n",
    "params = {\n",
    "    'scaling': [None, StandardScaler(), RobustScaler()],\n",
    "    'model__max_depth':[2, 5, 10, 15, 20, 25, 30, 40, 50, 75, 100, 150, None],\n",
    "    'model__max_features':['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "gs4 = GridSearchCV(modeling_pipe, params, verbose=1, cv=5, n_jobs=-1)\n",
    "gs4.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936616284739\n",
      "{'model__max_depth': 2, 'model__max_features': 'sqrt', 'scaling': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "print(gs4.best_score_)\n",
    "print(gs4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create predictions dataframe\n",
    "pred = pd.DataFrame()\n",
    "pred['Id'] = test_df.Id\n",
    "pred['Sale Condition'] = gs4.best_estimator_.predict(test_df)\n",
    "\n",
    "#to csv\n",
    "pred.to_csv('ClassSubs/DTClass.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.93567251462\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_not_abnormal</th>\n",
       "      <th>predicted_abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_abnormal</th>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_abnormal</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_not_abnormal  predicted_abnormal\n",
       "not_abnormal                     480                   0\n",
       "is_abnormal                       33                   0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('model', DecisionTreeClassifier(max_depth=2, max_features='sqrt'))\n",
    "])\n",
    "modeling_pipe.fit(Xtr, ytr)\n",
    "preds = modeling_pipe.predict(Xte)\n",
    "print('Accuracy', accuracy_score(yte, preds))\n",
    "\n",
    "conmat = np.array(confusion_matrix(yte, preds, labels=[0,1]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['not_abnormal', 'is_abnormal'],\n",
    "                         columns=['predicted_not_abnormal', 'predicted_abnormal'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the structure of the pipeline so it can be easily gridsearched\n",
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', None),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "#create parameters\n",
    "params = {\n",
    "    'scaling': [None, StandardScaler(), RobustScaler()],\n",
    "    'model__max_depth':[2, 5, 10, 15, 20, 25, 30, 40, 50, 75, 100, 150, None],\n",
    "    'model__max_features':['auto', 'sqrt', 'log2'],\n",
    "    'model__n_estimators': [int(x) for x in np.logspace(1, 3, 10)]\n",
    "}\n",
    "\n",
    "gs5 = GridSearchCV(modeling_pipe, params, verbose=1, cv=5, n_jobs=-1)\n",
    "gs5.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93759141882\n",
      "{'model__max_depth': 30, 'model__max_features': 'sqrt', 'model__n_estimators': 10, 'scaling': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)}\n"
     ]
    }
   ],
   "source": [
    "print(gs5.best_score_)\n",
    "print(gs5.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create predictions dataframe\n",
    "pred = pd.DataFrame()\n",
    "pred['Id'] = test_df.Id\n",
    "pred['Sale Condition'] = gs5.best_estimator_.predict(test_df)\n",
    "\n",
    "#to csv\n",
    "pred.to_csv('ClassSubs/RFClass.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.929824561404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_not_abnormal</th>\n",
       "      <th>predicted_abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_abnormal</th>\n",
       "      <td>477</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_abnormal</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_not_abnormal  predicted_abnormal\n",
       "not_abnormal                     477                   3\n",
       "is_abnormal                       33                   0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', RobustScaler()),\n",
    "    ('model', RandomForestClassifier(max_depth=30, max_features='sqrt', n_estimators=10))\n",
    "])\n",
    "modeling_pipe.fit(Xtr, ytr)\n",
    "preds = modeling_pipe.predict(Xte)\n",
    "print('Accuracy', accuracy_score(yte, preds))\n",
    "\n",
    "conmat = np.array(confusion_matrix(yte, preds, labels=[0,1]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['not_abnormal', 'is_abnormal'],\n",
    "                         columns=['predicted_not_abnormal', 'predicted_abnormal'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attempt to Account for Imbalanced Data**\n",
    "\n",
    "Without importing any special libraries, I am going to hack together a dataframe that has more abnormal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "fdf = pd.read_csv('datasets/train.csv')\n",
    "fdf['Sale Condition'] = fdf['Sale Condition'].apply(lambda x: 1 if x=='Abnorml' else 0)\n",
    "abnormls = fdf[fdf['Sale Condition']==1].copy()\n",
    "for i in range(0,4):\n",
    "    fdf = pd.concat((fdf, abnormls))\n",
    "\n",
    "# df now has 5x more abnormals\n",
    "#save the training X without either target variable, then save the encoded classifier target\n",
    "fX = fdf.drop(['Sale Condition', 'SalePrice'], axis=1)\n",
    "fX = fX.reindex()\n",
    "fy = fdf['Sale Condition']\n",
    "\n",
    "#train test split\n",
    "fXtr, fXte, fytr, fyte = train_test_split(fX, fy, random_state=42, stratify=fy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit to the monstrosity of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated Data Accuracy 0.998050682261\n",
      "Real Train Data Accuracy 0.998050682261\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_not_abnormal</th>\n",
       "      <th>predicted_abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_abnormal</th>\n",
       "      <td>479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_abnormal</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_not_abnormal  predicted_abnormal\n",
       "not_abnormal                     479                   1\n",
       "is_abnormal                        0                  33"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('model', RandomForestClassifier(max_depth=30, max_features='sqrt', n_estimators=10))\n",
    "])\n",
    "modeling_pipe.fit(fXtr, fytr)\n",
    "fpreds = modeling_pipe.predict(fXte)\n",
    "preds = modeling_pipe.predict(Xte)\n",
    "print('Duplicated Data Accuracy', accuracy_score(yte, preds))\n",
    "print('Real Train Data Accuracy', accuracy_score(yte, preds))\n",
    "\n",
    "conmat = np.array(confusion_matrix(yte, preds, labels=[0,1]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['not_abnormal', 'is_abnormal'],\n",
    "                         columns=['predicted_not_abnormal', 'predicted_abnormal'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like this methodology has merit, try a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create predictions dataframe\n",
    "pred = pd.DataFrame()\n",
    "pred['Id'] = test_df.Id\n",
    "pred['Sale Condition'] = modeling_pipe.predict(test_df)\n",
    "\n",
    "#to csv\n",
    "pred.to_csv('ClassSubs/fRFClass.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the structure of the pipeline so it can be easily gridsearched\n",
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', None),\n",
    "    #('selectkbest', SelectKBest(score_func=f_classif, k=5)),\n",
    "    ('model', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "#create parameters\n",
    "params = {\n",
    "    'scaling': [None, StandardScaler(), RobustScaler()],\n",
    "    #'selectkbest__k':[2, 5, 10, 25, 50, 75, 100, 150, 'all'],\n",
    "    #'model__base_estimator':[gs1.best_estimator_,gs2.best_estimator_, gs3.best_estimator_, \n",
    "    #                         gs4.best_estimator_],\n",
    "    'model__base_estimator': [LogisticRegression(), DecisionTreeClassifier()],\n",
    "    'model__n_estimators': [int(x) for x in np.logspace(1, 3, 10)]\n",
    "}\n",
    "\n",
    "gs7 = GridSearchCV(modeling_pipe, params, verbose=1, cv=5, n_jobs=-1)\n",
    "gs7.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939054119941\n",
      "{'model__base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), 'model__n_estimators': 10, 'scaling': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "print(gs7.best_score_)\n",
    "print(gs7.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create predictions dataframe\n",
    "pred = pd.DataFrame()\n",
    "pred['Id'] = test_df.Id\n",
    "pred['Sale Condition'] = gs7.best_estimator_.predict(test_df)\n",
    "\n",
    "#to csv\n",
    "pred.to_csv('ClassSubs/ABClass.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.929824561404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_not_abnormal</th>\n",
       "      <th>predicted_abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_abnormal</th>\n",
       "      <td>473</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_abnormal</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_not_abnormal  predicted_abnormal\n",
       "not_abnormal                     473                   7\n",
       "is_abnormal                       29                   4"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('model', AdaBoostClassifier(base_estimator=LogisticRegression(), n_estimators=10))\n",
    "])\n",
    "modeling_pipe.fit(Xtr, ytr)\n",
    "preds = modeling_pipe.predict(Xte)\n",
    "print('Accuracy', accuracy_score(yte, preds))\n",
    "\n",
    "conmat = np.array(confusion_matrix(yte, preds, labels=[0,1]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['not_abnormal', 'is_abnormal'],\n",
    "                         columns=['predicted_not_abnormal', 'predicted_abnormal'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the structure of the pipeline so it can be easily gridsearched\n",
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', None),\n",
    "    ('model', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "#create parameters\n",
    "params = {\n",
    "    'scaling': [None, StandardScaler(), RobustScaler()],\n",
    "    'model__max_depth':[2, 5, 10, 15, 20, 25, 30, 40, 50, 75, 100, 150, None],\n",
    "    'model__max_features':['auto', 'sqrt', 'log2'],\n",
    "    'model__n_estimators': [int(x) for x in np.linespace(1, 3, 10)]\n",
    "}\n",
    "\n",
    "gs8 = GridSearchCV(modeling_pipe, params, verbose=1, cv=5, n_jobs=-1)\n",
    "gs8.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.939054119941\n",
      "{'model__max_depth': 2, 'model__max_features': 'log2', 'model__n_estimators': 359, 'scaling': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "print(gs8.best_score_)\n",
    "print(gs8.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create predictions dataframe\n",
    "pred = pd.DataFrame()\n",
    "pred['Id'] = test_df.Id\n",
    "pred['Sale Condition'] = gs8.best_estimator_.predict(test_df)\n",
    "\n",
    "#to csv\n",
    "pred.to_csv('ClassSubs/GBClass.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.931773879142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_not_abnormal</th>\n",
       "      <th>predicted_abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_abnormal</th>\n",
       "      <td>476</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_abnormal</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_not_abnormal  predicted_abnormal\n",
       "not_abnormal                     476                   4\n",
       "is_abnormal                       31                   2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('model', GradientBoostingClassifier(max_depth=2, max_features='log2', n_estimators=359))\n",
    "])\n",
    "modeling_pipe.fit(Xtr, ytr)\n",
    "preds = modeling_pipe.predict(Xte)\n",
    "print('Accuracy', accuracy_score(yte, preds))\n",
    "\n",
    "conmat = np.array(confusion_matrix(yte, preds, labels=[0,1]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['not_abnormal', 'is_abnormal'],\n",
    "                         columns=['predicted_not_abnormal', 'predicted_abnormal'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attempt to Account for Imbalanced Data**\n",
    "\n",
    "Without importing any special libraries, I am going to hack together a dataframe that has more abnormal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training data\n",
    "fdf = pd.read_csv('datasets/train.csv')\n",
    "fdf['Sale Condition'] = fdf['Sale Condition'].apply(lambda x: 1 if x=='Abnorml' else 0)\n",
    "abnormls = fdf[fdf['Sale Condition']==1].copy()\n",
    "for i in range(0,1):\n",
    "    fdf = pd.concat((fdf, abnormls))\n",
    "\n",
    "# df now has 5x more abnormals\n",
    "#save the training X without either target variable, then save the encoded classifier target\n",
    "fX = fdf.drop(['Sale Condition', 'SalePrice'], axis=1)\n",
    "fX = fX.reindex()\n",
    "fy = fdf['Sale Condition']\n",
    "\n",
    "#train test split\n",
    "fXtr, fXte, fytr, fyte = train_test_split(fX, fy, random_state=42, stratify=fy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated Data Accuracy 0.988304093567\n",
      "Real Train Data Accuracy 0.988304093567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_not_abnormal</th>\n",
       "      <th>predicted_abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_abnormal</th>\n",
       "      <td>476</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_abnormal</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_not_abnormal  predicted_abnormal\n",
       "not_abnormal                     476                   4\n",
       "is_abnormal                        2                  31"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('model', GradientBoostingClassifier(max_depth=5, max_features='log2', n_estimators=300, subsample=.7))\n",
    "])\n",
    "modeling_pipe.fit(fXtr, fytr)\n",
    "fpreds = modeling_pipe.predict(fXte)\n",
    "preds = modeling_pipe.predict(Xte)\n",
    "print('Duplicated Data Accuracy', accuracy_score(yte, preds))\n",
    "print('Real Train Data Accuracy', accuracy_score(yte, preds))\n",
    "\n",
    "conmat = np.array(confusion_matrix(yte, preds, labels=[0,1]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['not_abnormal', 'is_abnormal'],\n",
    "                         columns=['predicted_not_abnormal', 'predicted_abnormal'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems promising, may as well try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    874\n",
       "1      5\n",
       "Name: Sale Condition, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create predictions dataframe\n",
    "pred = pd.DataFrame()\n",
    "pred['Id'] = test_df.Id\n",
    "\n",
    "pred['Sale Condition'] = m_preds = [0 if nabn >= .45 else 1 for nabn, abn in modeling_pipe.predict_proba(test_df)]\n",
    "\n",
    "#to csv\n",
    "pred.to_csv('ClassSubs/fGBClass.csv', index=False)\n",
    "pred['Sale Condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the structure of the pipeline so it can be easily gridsearched\n",
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', None),\n",
    "    #('selectkbest', SelectKBest(score_func=f_classif, k=5)),\n",
    "    ('model', VotingClassifier(estimators=[('logR',LogisticRegression()), ('DTree',DecisionTreeClassifier())]))\n",
    "    #('model', VotingClassifier(estimators=[gs1.best_estimator_,gs2.best_estimator_,\n",
    "    #                                        gs3.best_estimator_, gs4.best_estimator_]))\n",
    "])\n",
    "\n",
    "#create parameters\n",
    "params = {\n",
    "    'scaling': [None, StandardScaler(), RobustScaler()],\n",
    "    #'selectkbest__k':[5, 10, 25, 50, 75, 100, 150, 'all'],\n",
    "    'model__voting': ['hard', 'soft']\n",
    "}\n",
    "\n",
    "gs9 = GridSearchCV(modeling_pipe, params, verbose=1, cv=5, n_jobs=-1)\n",
    "gs9.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936616284739\n",
      "{'model__voting': 'hard', 'scaling': None}\n"
     ]
    }
   ],
   "source": [
    "print(gs9.best_score_)\n",
    "print(gs9.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create predictions dataframe\n",
    "pred = pd.DataFrame()\n",
    "pred['Id'] = test_df.Id\n",
    "pred['Sale Condition'] = gs9.best_estimator_.predict(test_df)\n",
    "\n",
    "#to csv\n",
    "pred.to_csv('ClassSubs/VoteClass.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.933723196881\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_not_abnormal</th>\n",
       "      <th>predicted_abnormal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not_abnormal</th>\n",
       "      <td>477</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_abnormal</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predicted_not_abnormal  predicted_abnormal\n",
       "not_abnormal                     477                   3\n",
       "is_abnormal                       31                   2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_pipe = Pipeline([\n",
    "    ('data', data_fu),\n",
    "    ('scaling', None),\n",
    "    ('model', VotingClassifier(estimators=[('logR',LogisticRegression()), ('DTree',DecisionTreeClassifier())], voting='hard'))\n",
    "])\n",
    "modeling_pipe.fit(Xtr, ytr)\n",
    "preds = modeling_pipe.predict(Xte)\n",
    "print('Accuracy', accuracy_score(yte, preds))\n",
    "\n",
    "conmat = np.array(confusion_matrix(yte, preds, labels=[0,1]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['not_abnormal', 'is_abnormal'],\n",
    "                         columns=['predicted_not_abnormal', 'predicted_abnormal'])\n",
    "confusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
